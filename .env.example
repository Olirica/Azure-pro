# Express
PORT=3000
HOST=0.0.0.0
LOG_LEVEL=info

# Azure Speech Service
SPEECH_KEY=your-azure-speech-key
SPEECH_REGION=your-azure-region

# Azure Translator
TRANSLATOR_KEY=your-azure-translator-key
TRANSLATOR_REGION=your-translator-region
TRANSLATOR_ENDPOINT=https://api.cognitive.microsofttranslator.com

# Optional: default voice used by the TTS queue
DEFAULT_TTS_VOICE=en-US-JennyNeural
DEFAULT_TTS_VOICE_FALLBACK=en-US-GuyNeural
DEFAULT_TTS_VOICE_FR_CA=fr-CA-SylvieNeural
# Other built-in defaults include en-CA-ClaraNeural, en-GB-RyanNeural,
# fr-FR-DeniseNeural, es-ES-AlvaroNeural, es-MX-JorgeNeural. Override as needed.

# Optional: Postgres for room registry (preferred for prod)
# Use Railway reference in your Node service: DATABASE_URL=$Postgres.DATABASE_URL
# Or public URL with sslmode=require
DATABASE_URL=

# Optional: Redis state store (for patches/tts cache). If unset, falls back to memory/FS.
REDIS_URL=redis://localhost:6379/0
REDIS_PREFIX=simo

# Admin access (required in production)
ADMIN_TOKEN=
NODE_ENV=production

# ============================================================================
# Tuning Profile: HYBRID (Dictation Quality at Conversation Speed)
# See .env.profiles for DICTATION, CONVERSATION, and HYBRID profiles
# ============================================================================

# Azure Recognition Mode (dictation | conversation | interactive)
RECOGNITION_MODE=dictation              # Use dictation for better punctuation

# Runtime tuning - OPTIMIZED FOR SIMULTANEOUS INTERPRETING FEEL
# Tuned for faster STT surfacing + earlier translations (48hr production event)
SPEECH_STABLE_PARTIALS=3                  # was 4 - faster partial stabilization
SPEECH_SEGMENTATION_SILENCE_MS=250        # was 1000 - much faster segmentation on pauses
SPEECH_INITIAL_SILENCE_MS=3000
SPEECH_END_SILENCE_MS=250                 # was 600 - faster utterance closing
FASTFINALS_STABLE_K=3
FASTFINALS_MIN_STABLE_MS=450              # was 500 - emit fast finals earlier
FASTFINALS_MIN_CHARS=22                   # was 35 - lower threshold for fast finals
FASTFINALS_MIN_WORDS=4                    # was 6 - emit on shorter segments
FASTFINALS_EMIT_THROTTLE_MS=600           # was 800 - faster fast-final cadence
FASTFINALS_PUNCT_STABLE_MS=250            # was 350 - quicker punctuation dwell
FASTFINALS_TAIL_GUARD_CHARS=8             # keep as-is - balanced protection
FASTFINALS_TAIL_GUARD_WORDS=1             # keep as-is - balanced protection
FASTFINALS_FORCE_EMIT_ON_PUNCT=true
SOFT_THROTTLE_MS=600                      # was 1000 - faster soft patch surfacing
SOFT_MIN_DELTA_CHARS=10                   # was 18 - show progress sooner
FINAL_DEBOUNCE_MS=180
MAX_UTTERANCE_DURATION_MS=6000            # was 7000-9000 - cap utterances at 6s to avoid monoliths
SPEECH_TOKEN_REFRESH_MS=540000
WS_PING_INTERVAL_MS=30000
PATCH_LRU_PER_ROOM=500

# TTS Smooth Speed Curve (replaces old binary throttle)
# TTS always plays at minimum 1.05x speed, smoothly ramping to 1.35x as backlog grows
TTS_BASE_SPEED=1.05                      # Base playback speed (always 5% faster)
TTS_BACKLOG_RAMP_START_SEC=5             # Start accelerating at 5s backlog
TTS_BACKLOG_RAMP_END_SEC=20              # Reach max speed at 20s backlog
TTS_MAX_SPEED=1.35                       # Maximum playback speed (35% faster, absolute cap)
TTS_MAX_SPEED_CHANGE_PERCENT=25          # Max 25% speed change per segment (smooth transitions)
TTS_BACKLOG_FALLBACK_VOICE=              # Optional: switch voice when accelerated (blank = keep same)
SPEECH_TTS_FORMAT=Audio24Khz48KBitRateMonoMp3
PHRASE_HINTS=Azure,OpenAI,Paralucent,Contoso
AUTO_DETECT_LANGS=en-US,fr-CA
TRANSLATOR_PROFANITY_ACTION=NoAction
TRANSLATOR_PROFANITY_MARKER=Asterisk
OPENAI_API_KEY=
OPENAI_TRANSLATE_MODEL=gpt-4o-mini
OPENAI_TRANSLATE_ENDPOINT=https://api.openai.com/v1/chat/completions
WS_VERBOSE_LOG=false

# ElevenLabs (optional)
# ELEVENLABS_API_KEY=
# ELEVENLABS_VOICE_FR_CA=NsFK0aDGLbVusA7tQfOB
# ELEVENLABS_MODEL_ID=eleven_multilingual_v2
# ELEVENLABS_TTS_ENDPOINT=https://api.elevenlabs.io/v1/text-to-speech
# ELEVENLABS_STABILITY=
# ELEVENLABS_SIMILARITY=

# Hybrid Translation Buffering (Smart segment merging)
# Enable intelligent segment merging for better translation context
# Display stays fast (~500ms) but translations wait briefly to merge segments
TRANSLATION_MERGE_ENABLED=true
TRANSLATION_MERGE_WINDOW_MS=900           # was 1500 - Wait up to 0.9s for simultaneous feel
TRANSLATION_MIN_MERGE_CHARS=50            # Only merge if result is 50+ chars
TRANSLATION_MAX_MERGE_COUNT=3             # Merge max 3 segments together

# Filler Word Filtering (Clean up speech artifacts)
# Automatically remove filler words ("uh", "um", "euh", etc.) from transcripts
FILTER_FILLER_WORDS=true                  # Enable/disable filler filtering
# FILLER_WORDS_EN=uh,um,like,you know    # Custom English fillers (optional)
# FILLER_WORDS_FR=euh,ben,genre,tu sais  # Custom French fillers (optional)

# Watchdog thresholds
WATCHDOG_EVENT_IDLE_MS=12000
WATCHDOG_PCM_IDLE_MS=7000
