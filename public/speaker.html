<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Simo by Canoë · Speaker</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      :root {
        color-scheme: light dark;
        font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
        line-height: 1.5;
      }
      body {
        margin: 0;
        padding: 1.5rem;
        background: #0f172a;
        color: #f1f5f9;
      }
      main {
        max-width: 960px;
        margin: 0 auto;
      }
      section {
        background: rgba(15, 23, 42, 0.6);
        border-radius: 12px;
        padding: 1.5rem;
        margin-bottom: 1.5rem;
        box-shadow: 0 25px 30px -24px rgba(15, 23, 42, 0.8);
        border: 1px solid rgba(148, 163, 184, 0.2);
      }
      h1,
      h2 {
        margin-top: 0;
      }
      label {
        display: block;
        margin-top: 0.75rem;
        font-weight: 600;
      }
      input,
      textarea {
        width: 100%;
        padding: 0.6rem 0.8rem;
        margin-top: 0.35rem;
        border-radius: 8px;
        border: 1px solid rgba(148, 163, 184, 0.3);
        background: rgba(15, 23, 42, 0.35);
        color: inherit;
      }
      button {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        padding: 0.6rem 1rem;
        border-radius: 8px;
        border: none;
        font-weight: 600;
        cursor: pointer;
        margin-right: 1rem;
        background: #38bdf8;
        color: #0f172a;
        transition: transform 120ms ease, box-shadow 120ms ease;
      }
      button[disabled] {
        opacity: 0.5;
        cursor: not-allowed;
      }
      button:hover:not([disabled]) {
        transform: translateY(-1px);
        box-shadow: 0 10px 18px -10px rgba(56, 189, 248, 0.9);
      }
      ul {
        list-style: none;
        padding: 0;
        margin: 0;
      }
      li {
        padding: 0.75rem 1rem;
        margin-bottom: 0.5rem;
        border-radius: 8px;
        border: 1px solid rgba(148, 163, 184, 0.25);
        background: rgba(15, 23, 42, 0.3);
      }
      li[data-stage="soft"] {
        border-color: rgba(94, 234, 212, 0.2);
      }
      li[data-stage="hard"] {
        border-color: rgba(186, 230, 253, 0.45);
        background: rgba(14, 116, 144, 0.2);
      }
      .status {
        display: inline-flex;
        align-items: center;
        gap: 0.35rem;
        font-size: 0.95rem;
        margin-right: 1.25rem;
      }
      .badge {
        padding: 0.15rem 0.55rem;
        border-radius: 999px;
        font-size: 0.75rem;
        text-transform: uppercase;
        letter-spacing: 0.07em;
        background: rgba(56, 189, 248, 0.2);
        border: 1px solid rgba(56, 189, 248, 0.4);
      }
      .stack {
        display: flex;
        flex-wrap: wrap;
        gap: 1rem;
        align-items: center;
      }
      .stack input {
        max-width: 220px;
      }
      .stack label {
        margin-top: 0;
      }
      pre {
        background: rgba(15, 23, 42, 0.6);
        padding: 1rem;
        border-radius: 8px;
        overflow-x: auto;
        border: 1px solid rgba(148, 163, 184, 0.18);
      }
      small {
        color: rgba(148, 163, 184, 0.8);
      }
    </style>
  </head>
  <body>
    <main>
      <section>
        <h1>Speaker Console</h1>
        <p>Start your microphone capture, share the live transcript, and let listeners follow along.</p>
        <div class="stack">
          <div>
            <label for="roomId">Room ID</label>
            <input id="roomId" type="text" value="demo-room" />
          </div>
          <div>
            <label for="sourceLang">Source language (BCP-47)</label>
            <input id="sourceLang" type="text" value="en-CA" />
          </div>
          <div>
            <label for="targetLangs">Target languages (comma separated)</label>
            <input id="targetLangs" type="text" value="fr-CA" />
          </div>
          <div>
            <label for="micSelect">Microphone</label>
            <select id="micSelect" style="width: 100%; padding: 0.6rem 0.8rem; margin-top: 0.35rem; border-radius: 8px; border: 1px solid rgba(148, 163, 184, 0.3); background: rgba(15, 23, 42, 0.35); color: inherit;">
              <option value="">Default microphone</option>
            </select>
          </div>
        </div>
        <div class="stack" style="margin-top: 1.25rem">
          <div class="status">
            <span class="badge" id="recognitionStatus">Idle</span>
            <span id="telemetry">—</span>
          </div>
          <button id="startBtn">Start capture</button>
          <button id="stopBtn" disabled>Stop</button>
        </div>
      </section>

      <section>
        <h2>Live transcript</h2>
        <ul id="transcript"></ul>
      </section>

      <section>
        <h2>Debug</h2>
        <button id="copyDebugBtn" style="margin-bottom: 1rem; background: rgba(148, 163, 184, 0.2); color: inherit;">
          Copy debug log
        </button>
        <pre id="debugLog">Waiting…</pre>
        <small>Token acquisition, SDK events, and merge decisions appear here.</small>
      </section>
    </main>

    <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
    <script>
      (() => {
        const logArea = document.getElementById('debugLog');
        const transcriptList = document.getElementById('transcript');
        const recognitionStatus = document.getElementById('recognitionStatus');
        const telemetry = document.getElementById('telemetry');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const copyDebugBtn = document.getElementById('copyDebugBtn');

        const state = {
          recognizer: null,
          ws: null,
          sessionId: null,
          currentUtteranceId: null,  // Stable ID for current utterance
          rev: 0,  // Revision counter (increments within same utteranceId)
          lastSoftEmitAt: 0,
          lastSoftText: '',
          lastPartialFull: '',
          prefix: createPrefixState(),
          fastFinals: null,
          roomId: null,
          sourceLang: null,
          targetLangs: [],
          heartbeatTimer: null,
          heartbeatIntervalMs: 2500,
          itemsByUnit: new Map(),
          config: null,
          tokenTimer: null,
          tokenRegion: null,
          finalTimer: null,
          phraseList: null,
          phraseHints: [],
          autoDetectLangs: [],
          patchSourceLang: null
        };

        const DEFAULT_FAST_FINALS = Object.freeze({
          stableK: 3,
          minStableMs: 600,
          minChars: 28,
          minWords: 6,
          emitThrottleMs: 700,
          punctStableMs: 350
        });

        const DEFAULT_CONFIG = {
          stablePartials: 4,
          segmentationSilenceMs: 500,
          initialSilenceMs: 3000,
          endSilenceMs: 350,
          softThrottleMs: 1000,
          softMinDeltaChars: 18,
          speechTokenRefreshMs: 540000,
          wsPingIntervalMs: 30000,
          ttsMaxBacklogSec: 8,
          ttsResumeBacklogSec: 4,
          ttsRateBoostPercent: 10,
          finalDebounceMs: 180,
          phraseHints: [],
          autoDetectLangs: [],
          fastFinals: { ...DEFAULT_FAST_FINALS }
        };

        async function loadConfig() {
          if (state.config) {
            return state.config;
          }
          try {
            const res = await fetch('/api/config', { cache: 'no-store' });
            if (!res.ok) {
              throw new Error(`Config request failed (${res.status})`);
            }
            const data = await res.json();
            const speechTunables =
              data && typeof data.speechTunables === 'object' && data.speechTunables
                ? data.speechTunables
                : {};
            const mergedConfig = { ...DEFAULT_CONFIG, ...data };
            const coerce = (value, fallback) => {
              const num = Number(value);
              return Number.isFinite(num) ? num : fallback;
            };
            mergedConfig.stablePartials = coerce(
              data.stablePartials ?? speechTunables.stablePartials,
              DEFAULT_CONFIG.stablePartials
            );
            mergedConfig.segmentationSilenceMs = coerce(
              data.segmentationSilenceMs ?? speechTunables.segmentationSilenceMs,
              DEFAULT_CONFIG.segmentationSilenceMs
            );
            mergedConfig.initialSilenceMs = coerce(
              data.initialSilenceMs ?? speechTunables.initialSilenceMs,
              DEFAULT_CONFIG.initialSilenceMs
            );
            mergedConfig.endSilenceMs = coerce(
              data.endSilenceMs ?? speechTunables.endSilenceMs,
              DEFAULT_CONFIG.endSilenceMs
            );
            mergedConfig.ttsMaxBacklogSec = coerce(
              data.ttsMaxBacklogSec,
              DEFAULT_CONFIG.ttsMaxBacklogSec
            );
            mergedConfig.ttsResumeBacklogSec = coerce(
              data.ttsResumeBacklogSec,
              DEFAULT_CONFIG.ttsResumeBacklogSec
            );
            mergedConfig.ttsRateBoostPercent = coerce(
              data.ttsRateBoostPercent,
              DEFAULT_CONFIG.ttsRateBoostPercent
            );
            const incomingFastFinals =
              data && typeof data.fastFinals === 'object' && data.fastFinals ? data.fastFinals : {};
            const fastFinals = {
              stableK: coerce(incomingFastFinals.stableK, DEFAULT_FAST_FINALS.stableK),
              minStableMs: coerce(incomingFastFinals.minStableMs, DEFAULT_FAST_FINALS.minStableMs),
              minChars: coerce(incomingFastFinals.minChars, DEFAULT_FAST_FINALS.minChars),
              minWords: coerce(incomingFastFinals.minWords, DEFAULT_FAST_FINALS.minWords),
              emitThrottleMs: coerce(
                incomingFastFinals.emitThrottleMs,
                DEFAULT_FAST_FINALS.emitThrottleMs
              ),
              punctStableMs: coerce(
                incomingFastFinals.punctStableMs,
                DEFAULT_FAST_FINALS.punctStableMs,
                0
              ),
              tailGuardChars: coerce(
                incomingFastFinals.tailGuardChars,
                DEFAULT_FAST_FINALS.tailGuardChars,
                0
              ),
              tailGuardWords: coerce(
                incomingFastFinals.tailGuardWords,
                DEFAULT_FAST_FINALS.tailGuardWords,
                0
              )
            };
            mergedConfig.fastFinals = { ...fastFinals };
            state.config = mergedConfig;
            state.fastFinals = fastFinals;
            state.phraseHints = Array.isArray(state.config.phraseHints)
              ? state.config.phraseHints
              : [];
            if (!state.phraseHints.some((hint) => hint.trim().toLowerCase() === 'session')) {
              state.phraseHints.push('session');
            }
            state.autoDetectLangs = Array.isArray(state.config.autoDetectLangs)
              ? state.config.autoDetectLangs
              : [];
            log('Runtime config loaded', state.config);
          } catch (err) {
            state.config = { ...DEFAULT_CONFIG, fastFinals: { ...DEFAULT_FAST_FINALS } };
            state.fastFinals = { ...DEFAULT_FAST_FINALS };
            state.phraseHints = [];
            state.autoDetectLangs = [];
            log('Failed to load config, falling back to defaults.', { error: err?.message });
          }
          const heartbeat = state.config.wsPingIntervalMs || DEFAULT_CONFIG.wsPingIntervalMs;
          state.heartbeatIntervalMs = Math.max(Math.floor(heartbeat / 3), 2000);
          return state.config;
        }

        function log(message, context = {}) {
          // Compact timestamp: HH:MM:SS.mmm
          const now = new Date();
          const timestamp = now.toTimeString().slice(0, 8) + '.' + now.getMilliseconds().toString().padStart(3, '0');
          const entry = `[${timestamp}] ${message}${
            Object.keys(context).length ? ` ${JSON.stringify(context)}` : ''
          }`;
          if (logArea.textContent === 'Waiting…') {
            logArea.textContent = entry;
          } else {
            logArea.textContent += `\n${entry}`;
          }
          logArea.scrollTop = logArea.scrollHeight;
          console.debug('[speaker]', message, context);
        }

        function setStatus(text) {
          recognitionStatus.textContent = text;
        }

        function setTelemetry(text) {
          telemetry.textContent = text;
        }

        function normalize(text) {
          return (text || '')
            .toLowerCase()
            .replace(/[“”"']/g, '')
            .replace(/[\p{P}\p{S}]+/gu, ' ')
            .replace(/\s+/g, ' ')
            .trim();
        }

        function dedupeContinuation(previous, incoming) {
          const next = (incoming || '').trim();
          if (!previous) {
            return next;
          }
          const prev = previous.trim();
          if (!prev) {
            return next;
          }
          if (next.startsWith(prev)) {
            return next;
          }
          const normPrev = normalize(prev);
          const normNext = normalize(next);
          if (!normPrev || !normNext) {
            return next;
          }
          let i = 0;
          while (i < normPrev.length && i < normNext.length && normPrev[i] === normNext[i]) {
            i += 1;
          }
          const overlapRatio = i / Math.max(normPrev.length, 1);
          if (overlapRatio >= 0.8) {
            return `${prev}${next.slice(i)}`;
          }
          return next;
        }

        function parseTargetLangs(value) {
          return value
            .split(',')
            .map((lang) => lang.trim())
            .filter(Boolean);
        }

        function splitSentences(text) {
          if (!text) {
            return [];
          }
          const matches = text.match(/[^.!?]+[.!?]+(?:\s+|$)|[^.!?]+$/g);
          if (!matches) {
            return [text.trim()];
          }

          // Filter out fragments (lowercase start suggesting continuation)
          const sentences = matches.map((s) => s.trim()).filter(Boolean);
          const filtered = [];

          for (let i = 0; i < sentences.length; i++) {
            const sentence = sentences[i];
            const startsWithLowercase = /^[a-z]/.test(sentence);

            // If it starts with lowercase and isn't the first sentence,
            // merge it with the next sentence (or previous if it's last)
            if (startsWithLowercase && sentences.length > 1) {
              // Try to merge with next sentence if available
              if (i + 1 < sentences.length) {
                sentences[i + 1] = sentence + ' ' + sentences[i + 1];
                continue; // Skip adding this fragment
              }
              // Otherwise merge with previous
              else if (filtered.length > 0) {
                filtered[filtered.length - 1] += ' ' + sentence;
                continue;
              }
            }

            filtered.push(sentence);
          }

          return filtered;
        }

        function computeTimestamps(result) {
          if (!result) return undefined;
          const offsetMs = Math.floor(result.offset / 10000);
          const durationMs = Math.floor(result.duration / 10000);
          return { t0: offsetMs, t1: offsetMs + durationMs };
        }

        // Generate ULID-style utteranceId (timestamp + random)
        function generateUtteranceId() {
          const timestamp = Date.now().toString(36).toUpperCase();
          const random = Math.random().toString(36).substring(2, 10).toUpperCase();
          return `U${timestamp}${random}`;
        }

        function createPrefixState() {
          return {
            ring: [],
            committedChars: 0,
            committedRaw: '',
            lastStableLen: 0,
            lastStableAt: 0,
            lastCandidateEnd: 0,
            candidateStableAt: 0,
            lastEmitAt: 0,
            lastEmittedText: '' // Track last emitted text to prevent duplicates
          };
        }

        function getFastFinalsConfig() {
          const cfg = state.fastFinals || DEFAULT_FAST_FINALS;
          const coerce = (value, fallback, min = 0) => {
            const num = Number(value);
            if (!Number.isFinite(num)) {
              return fallback;
            }
            return Math.max(num, min);
          };
          return {
            stableK: coerce(cfg.stableK, DEFAULT_FAST_FINALS.stableK, 1),
            minStableMs: coerce(cfg.minStableMs, DEFAULT_FAST_FINALS.minStableMs, 0),
            minChars: coerce(cfg.minChars, DEFAULT_FAST_FINALS.minChars, 1),
            minWords: coerce(cfg.minWords, DEFAULT_FAST_FINALS.minWords, 1),
            emitThrottleMs: coerce(cfg.emitThrottleMs, DEFAULT_FAST_FINALS.emitThrottleMs, 0),
            punctStableMs: coerce(
              cfg.punctStableMs,
              DEFAULT_FAST_FINALS.punctStableMs,
              0
            ),
            tailGuardChars: coerce(cfg.tailGuardChars, DEFAULT_FAST_FINALS.tailGuardChars, 0),
            tailGuardWords: coerce(cfg.tailGuardWords, DEFAULT_FAST_FINALS.tailGuardWords, 0)
          };
        }

        function resetPrefixState() {
          state.prefix = createPrefixState();
        }

        function updatePrefixRingSnapshot(snapshot) {
          const ring = state.prefix.ring;
          ring.push(snapshot);
          const { stableK } = getFastFinalsConfig();
          while (ring.length > stableK) {
            ring.shift();
          }
        }

        function stablePrefixLength() {
          const ring = state.prefix.ring;
          if (!ring.length) {
            return 0;
          }
          let prefix = ring[0] || '';
          for (let i = 1; i < ring.length && prefix; i += 1) {
            const candidate = ring[i] || '';
            let j = 0;
            const max = Math.min(prefix.length, candidate.length);
            while (j < max && prefix[j] === candidate[j]) {
              j += 1;
            }
            prefix = prefix.slice(0, j);
          }
          return prefix.length;
        }

        function lastBoundaryBefore(text, idx) {
          const slice = text.slice(0, idx);
          const terminal = Math.max(slice.lastIndexOf('.'), slice.lastIndexOf('!'), slice.lastIndexOf('?'));
          if (terminal >= 0) {
            return terminal + 1;
          }
          const secondary = Math.max(slice.lastIndexOf(':'), slice.lastIndexOf(';'));
          if (secondary >= 0) {
            return secondary + 1;
          }
          return -1;
        }

        function countWords(text) {
          if (!text) {
            return 0;
          }
          const tokens = text.trim().match(/\S+/g);
          return tokens ? tokens.length : 0;
        }

        function applyTailGuards(fullText, startIdx, endIdx, config) {
          if (!fullText || endIdx <= startIdx) {
            return startIdx;
          }
          let candidate = endIdx;
          const guardChars = Math.max(Number(config.tailGuardChars || 0), 0);
          if (guardChars > 0 && candidate - startIdx > guardChars) {
            candidate = Math.max(startIdx, candidate - guardChars);
          }
          const guardWords = Math.max(Number(config.tailGuardWords || 0), 0);
          if (guardWords > 0) {
            const slice = fullText.slice(startIdx, candidate);
            const words = slice.match(/\S+/g) || [];
            if (words.length > guardWords) {
              const keepCount = words.length - guardWords;
              let keepEnd = startIdx;
              const matcher = /\S+/g;
              let match;
              let seen = 0;
              while (seen < keepCount && (match = matcher.exec(slice))) {
                seen += 1;
                keepEnd = startIdx + match.index + match[0].length;
              }
              candidate = Math.max(startIdx, Math.min(candidate, keepEnd));
            } else {
              candidate = startIdx;
            }
          }
          return candidate;
        }

        function computeFinalRemainder(finalText) {
          if (!finalText) {
            return '';
          }
          const prefixState = state.prefix;
          const rawCommitted = prefixState.committedRaw || '';
          if (rawCommitted && finalText.startsWith(rawCommitted)) {
            return finalText.slice(rawCommitted.length).trim();
          }
          if (prefixState.committedChars) {
            return finalText.slice(prefixState.committedChars).trim();
          }
          return finalText.trim();
        }

        async function emitHardSegment(text, result, options = {}) {
          const cleaned = (text || '').trim();
          if (!cleaned) {
            return null;
          }

          // Each hard segment gets its own unique utteranceId
          // (Don't reuse currentUtteranceId - that's for partials only)
          const newUtteranceId = generateUtteranceId();

          const utteranceId = await postPatch(cleaned, 'hard', result, {
            meta: options.meta,
            targets: options.targets,
            srcLang: options.srcLang,
            utteranceId: newUtteranceId
          });

          if (!utteranceId) {
            log('Hard segment POST failed', { length: cleaned.length });
            return null;
          }

          // Always reset utteranceId after emitting a hard segment
          // (Next partial will start a new utterance)
          state.currentUtteranceId = null;
          state.rev = 0;
          state.lastSoftText = '';
          state.lastSoftEmitAt = 0;

          if (options.isPrefix) {
            const prefixState = state.prefix;
            const nowTs = typeof options.now === 'number' ? options.now : performance.now();
            if (typeof options.commitEnd === 'number') {
              prefixState.committedChars = options.commitEnd;
              prefixState.lastStableLen = options.commitEnd;
              prefixState.lastCandidateEnd = options.commitEnd;
            }
            if (options.rawSlice) {
              prefixState.committedRaw += options.rawSlice;
            }
            prefixState.lastEmitAt = nowTs;
            prefixState.lastStableAt = nowTs;
            prefixState.candidateStableAt = nowTs;
            log('Prefix committed', {
              utteranceId,
              length: cleaned.length,
              committedChars: prefixState.committedChars
            });
          }

          return utteranceId;
        }

        async function postPatch(text, stage, result, options = {}) {
          if (!text) {
            return null;
          }

          // If caller provided explicit utteranceId (e.g., for hard finals), use rev: 0
          // Otherwise, use/create currentUtteranceId and increment rev
          let utteranceId, rev;

          if (options.utteranceId) {
            // Explicit utteranceId provided (hard segment) - start fresh at rev: 0
            utteranceId = options.utteranceId;
            rev = 0;
          } else {
            // No explicit utteranceId (soft patch) - use/create current and increment
            if (!state.currentUtteranceId) {
              state.currentUtteranceId = generateUtteranceId();
              state.rev = 0;
            }
            utteranceId = state.currentUtteranceId;
            rev = state.rev;
          }

          const targets = Array.isArray(options.targets) ? options.targets : state.targetLangs;

          const patch = {
            utteranceId,
            stage,
            op: 'replace',
            rev,
            text,
            srcLang: options.srcLang ?? state.patchSourceLang ?? state.sourceLang,
            isFinal: stage === 'hard',
            ts: computeTimestamps(result)
          };

          if (options.meta && typeof options.meta === 'object') {
            patch.meta = options.meta;
          }

          const payload = {
            roomId: state.roomId,
            targets,
            patch
          };

          try {
            const res = await fetch('/api/segments', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(payload)
            });

            if (!res.ok) {
              let body = null;
              try {
                body = await res.json();
              } catch (parseErr) {
                body = await res.text().catch(() => null);
              }
              log('Patch POST failed', { status: res.status, body });
              return null;
            }

            // Only increment revision if we're using currentUtteranceId (soft patches)
            // Hard segments get new utteranceId each time
            if (!options.utteranceId) {
              state.rev++;
            }

            return utteranceId;
          } catch (err) {
            log('Patch POST error', { error: err?.message });
          }
          return null;
        }

        function renderPatch(patch) {
          const utterId = patch.utteranceId || patch.unitId;
          if (!utterId) {
            return;
          }

          if (patch.stage !== 'hard') {
            log('Soft patch (hidden)', {
              utteranceId: utterId,
              text: patch.text?.substring(0, 40),
              rev: patch.rev ?? patch.version
            });
            return;
          }

          // Get or create the current paragraph
          let currentParagraph = transcriptList.lastElementChild;

          // Create new paragraph if none exists or if this is a new speaking session
          // (detect pause by checking if last update was > 5 seconds ago)
          const now = Date.now();
          const lastUpdate = currentParagraph?.dataset.lastUpdate ? parseInt(currentParagraph.dataset.lastUpdate) : 0;
          const timeSinceLastUpdate = now - lastUpdate;

          if (!currentParagraph || timeSinceLastUpdate > 5000) {
            currentParagraph = document.createElement('li');
            currentParagraph.dataset.lastUpdate = now;
            transcriptList.appendChild(currentParagraph);
          } else {
            currentParagraph.dataset.lastUpdate = now;
          }

          // Append text with space separator
          const currentText = currentParagraph.textContent;
          let textToAppend = patch.text;

          // Capitalize first letter if this is the start of a paragraph
          if (!currentText && textToAppend) {
            textToAppend = textToAppend.charAt(0).toUpperCase() + textToAppend.slice(1);
          }

          currentParagraph.textContent = currentText
            ? `${currentText} ${textToAppend}`
            : textToAppend;

          currentParagraph.dataset.stage = patch.stage;

          // Track this utterance
          state.itemsByUnit.set(utterId, currentParagraph);

          log('Hard patch appended to paragraph', {
            utteranceId: utterId,
            text: patch.text?.substring(0, 50),
            paragraphLength: currentParagraph.textContent.length,
            rev: patch.rev ?? patch.version
          });

          // Cleanup old paragraphs to prevent browser slowdown
          cleanupOldParagraphs();
        }

        function cleanupOldParagraphs() {
          const MAX_PARAGRAPHS = 20; // Keep last 20 paragraphs (live streaming focus)
          const paragraphs = transcriptList.querySelectorAll('li');

          if (paragraphs.length > MAX_PARAGRAPHS) {
            const removeCount = paragraphs.length - MAX_PARAGRAPHS;
            for (let i = 0; i < removeCount; i++) {
              paragraphs[i].remove();
            }
            log('Cleaned up old paragraphs', {
              removed: removeCount,
              remaining: MAX_PARAGRAPHS
            });
          }
        }

        function attachWebSocket() {
          if (state.ws) {
            state.ws.close();
          }
          const wsUrl = `${location.protocol === 'https:' ? 'wss' : 'ws'}://${location.host}/ws?room=${
            state.roomId
          }&role=speaker&lang=source`;
          const socket = new WebSocket(wsUrl);
          socket.onopen = () => log('Speaker WS connected');
          socket.onclose = () => log('Speaker WS closed');
          socket.onerror = (event) => log('Speaker WS error', { event });
          socket.onmessage = (event) => {
            try {
              const message = JSON.parse(event.data);
              if (message.type === 'patch') {
                renderPatch(message.payload);
              } else if (message.type === 'watchdog') {
                log('Watchdog ping', message.payload);
              } else if (message.type === 'reset') {
                state.itemsByUnit.clear();
                transcriptList.innerHTML = '';
                log('Transcript reset by server.');
              }
            } catch (err) {
              log('WS message parse failed', { error: err?.message });
            }
          };
          state.ws = socket;
        }

        function startHeartbeat() {
          stopHeartbeat();
          const interval = state.heartbeatIntervalMs || 2500;
          state.heartbeatTimer = setInterval(() => {
            if (state.ws && state.ws.readyState === WebSocket.OPEN) {
              state.ws.send(JSON.stringify({ type: 'heartbeat', payload: { pcm: true } }));
            }
          }, interval);
        }

        function stopHeartbeat() {
          if (state.heartbeatTimer) {
            clearInterval(state.heartbeatTimer);
            state.heartbeatTimer = null;
          }
        }

        function clearTokenRefresh() {
          if (state.tokenTimer) {
            clearInterval(state.tokenTimer);
            state.tokenTimer = null;
          }
        }

        function scheduleTokenRefresh() {
          clearTokenRefresh();
          const config = state.config || DEFAULT_CONFIG;
          const refreshWindow = config.speechTokenRefreshMs || DEFAULT_CONFIG.speechTokenRefreshMs;
          const interval = Math.max(refreshWindow - 10000, 60000);
          state.tokenTimer = setInterval(async () => {
            if (!state.recognizer) {
              return;
            }
            try {
              const { token } = await acquireToken({ quiet: true });
              if (token) {
                state.recognizer.authorizationToken = token;
              }
            } catch (err) {
              log('Token refresh failed', { error: err?.message });
            }
          }, interval);
        }

        async function acquireToken({ quiet = false } = {}) {
          const res = await fetch('/api/speech/token', { method: 'POST' });
          if (!res.ok) {
            throw new Error(`Token request failed with status ${res.status}`);
          }
          const body = await res.json();
          if (!body?.token || !body?.region) {
            throw new Error('Token response missing token/region.');
          }
          if (!quiet) {
            log('Token acquired', { region: body.region, expiresIn: body.expiresInSeconds });
          }
          return body;
        }

        async function start() {
          startBtn.disabled = true;
          stopBtn.disabled = false;
          state.roomId = document.getElementById('roomId').value.trim() || 'demo-room';
          const inputSourceLang = document.getElementById('sourceLang').value.trim() || 'en-US';
          state.sourceLang = inputSourceLang;
          state.patchSourceLang = inputSourceLang;
          state.targetLangs = parseTargetLangs(document.getElementById('targetLangs').value);
          state.sessionId = crypto.randomUUID();
          state.currentUtteranceId = null;
          state.rev = 0;
          state.lastSoftEmitAt = 0;
          state.lastSoftText = '';
          state.lastPartialFull = '';
          resetPrefixState();
          state.itemsByUnit.clear();
          transcriptList.innerHTML = '';

          try {
            const config = await loadConfig();
            setStatus('Authorising…');
            const { token, region } = await acquireToken();
            state.tokenRegion = region;

            const speechConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(token, region);
            const useAutoDetect =
              inputSourceLang.toLowerCase() === 'auto' && state.autoDetectLangs.length >= 2;
            if (useAutoDetect) {
              state.sourceLang = state.autoDetectLangs[0] || 'en-US';
              state.patchSourceLang = undefined;
            } else {
              state.sourceLang = inputSourceLang;
              state.patchSourceLang = state.sourceLang;
            }
            if (!useAutoDetect) {
              speechConfig.speechRecognitionLanguage = state.sourceLang;
            }
            speechConfig.outputFormat = SpeechSDK.OutputFormat.Detailed;
            speechConfig.setProperty(
              SpeechSDK.PropertyId.SpeechServiceResponse_StablePartialResultThreshold,
              String(config.stablePartials ?? DEFAULT_CONFIG.stablePartials)
            );
            speechConfig.setProperty(
              SpeechSDK.PropertyId.Speech_SegmentationSilenceTimeoutMs,
              String(config.segmentationSilenceMs ?? DEFAULT_CONFIG.segmentationSilenceMs)
            );
            speechConfig.setProperty(
              SpeechSDK.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs,
              String(config.initialSilenceMs ?? DEFAULT_CONFIG.initialSilenceMs)
            );
            speechConfig.setProperty(
              SpeechSDK.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs,
              String(config.endSilenceMs ?? DEFAULT_CONFIG.endSilenceMs)
            );
            speechConfig.setProperty(
              SpeechSDK.PropertyId.SpeechServiceResponse_RequestSentenceBoundary,
              'true'
            );
            speechConfig.setProperty(
              SpeechSDK.PropertyId.SpeechServiceResponse_RequestWordBoundary,
              'true'
            );
            speechConfig.setProperty(
              SpeechSDK.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary,
              'true'
            );

            // TEMPORARY: Revert to original simple audio config to test if device selection broke it
            log('Creating audio config from default microphone (original method)');
            const audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();

            let recognizer;
            if (useAutoDetect) {
              const candidates = state.autoDetectLangs.slice(0, 4);
              const autoDetectConfig = SpeechSDK.AutoDetectSourceLanguageConfig.fromLanguages(
                candidates
              );
              recognizer =
                typeof SpeechSDK.SpeechRecognizer.FromConfig === 'function'
                  ? SpeechSDK.SpeechRecognizer.FromConfig(
                      speechConfig,
                      autoDetectConfig,
                      audioConfig
                    )
                  : new SpeechSDK.SpeechRecognizer(speechConfig, autoDetectConfig, audioConfig);
            } else {
              recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);
            }
            state.recognizer = recognizer;
            if (state.phraseList && typeof state.phraseList.clear === 'function') {
              state.phraseList.clear();
            }
            if (Array.isArray(state.phraseHints) && state.phraseHints.length) {
              try {
                const phraseList = SpeechSDK.PhraseListGrammar.fromRecognizer(recognizer);
                state.phraseHints.slice(0, 200).forEach((hint) => phraseList.addPhrase(hint));
                state.phraseList = phraseList;
              } catch (err) {
                log('Failed to apply phrase hints', { error: err?.message });
              }
            }

            attachWebSocket();
            startHeartbeat();

            recognizer.recognizing = (_, event) => {
              const partial = event?.result?.text || '';
              const trimmed = partial.trim();
              if (!trimmed) {
                return;
              }

              // Log partials occasionally (not every single one to avoid spam)
              if (Math.random() < 0.1) {
                log('Recognizing (partial)', { text: trimmed.substring(0, 40) + '...' });
              }
              const previous = state.lastPartialFull || '';
              const merged = dedupeContinuation(previous, trimmed);
              if (!merged) {
                return;
              }
              state.lastPartialFull = merged;
              updatePrefixRingSnapshot(merged);

              const now = performance.now();
              const prefixState = state.prefix;
              const fastConfig = getFastFinalsConfig();
              const stableLen = stablePrefixLength();

              // Debug: Log ring buffer state occasionally
              if (Math.random() < 0.05) {
                log('Prefix ring state', {
                  ringSize: prefixState.ring.length,
                  stableLen,
                  committedChars: prefixState.committedChars,
                  merged: merged.substring(0, 40)
                });
              }

              if (stableLen !== prefixState.lastStableLen) {
                prefixState.lastStableLen = stableLen;
                prefixState.lastStableAt = now;
              }
              const boundary =
                stableLen > prefixState.committedChars
                  ? lastBoundaryBefore(merged, stableLen)
                  : -1;
              let candidateEnd = boundary >= 0 ? boundary : stableLen;
              if (boundary < 0) {
                candidateEnd = applyTailGuards(
                  merged,
                  prefixState.committedChars,
                  candidateEnd,
                  fastConfig
                );
              }
              if (candidateEnd < prefixState.committedChars) {
                candidateEnd = prefixState.committedChars;
              }
              if (candidateEnd !== prefixState.lastCandidateEnd) {
                prefixState.lastCandidateEnd = candidateEnd;
                prefixState.candidateStableAt = now;
              }
              if (stableLen > prefixState.committedChars) {
                const commitEnd = candidateEnd;
                if (commitEnd > prefixState.committedChars) {
                  const rawSlice = merged.slice(prefixState.committedChars, commitEnd);
                  const segment = rawSlice.trim();
                  const throttleOk = now - prefixState.lastEmitAt >= fastConfig.emitThrottleMs;
                  const isPunctCut = boundary >= 0;
                  const neededStable = isPunctCut
                    ? fastConfig.punctStableMs
                    : fastConfig.minStableMs;
                  const stableOk =
                    now - (prefixState.candidateStableAt || 0) >= neededStable;
                  const lengthOk =
                    boundary >= 0 ||
                    (segment.length >= fastConfig.minChars && countWords(segment) >= fastConfig.minWords);

                  // Debug fast-finals decision occasionally
                  if (Math.random() < 0.05) {
                    log('Fast-finals check', {
                      segment: segment.substring(0, 30),
                      throttleOk,
                      stableOk,
                      lengthOk,
                      isPunct: boundary >= 0
                    });
                  }

                  // Prevent duplicate emissions of the exact same text
                  const isDuplicate = segment === prefixState.lastEmittedText;

                  if (segment && throttleOk && stableOk && lengthOk && !isDuplicate) {
                    log('🚀 FAST-FINAL (prefix commit)', { segment: segment.substring(0, 50) });

                    // Update lastEmittedText IMMEDIATELY (before async call)
                    prefixState.lastEmittedText = segment;

                    emitHardSegment(segment, event.result, {
                      isPrefix: true,
                      rawSlice,
                      commitEnd,
                      now
                    });
                  } else if (isDuplicate) {
                    log('Skipping duplicate fast-final', { segment: segment.substring(0, 30) });
                  }
                }
              }

              const tail = merged.slice(prefixState.committedChars).trim();
              const config = state.config || DEFAULT_CONFIG;
              const softThrottle =
                config.softThrottleMs ?? DEFAULT_CONFIG.softThrottleMs;
              const minDelta =
                config.softMinDeltaChars ?? DEFAULT_CONFIG.softMinDeltaChars;
              const delta = tail.length - state.lastSoftText.length;
              const charTrigger = delta >= minDelta;
              const punctuationTrigger = /[.?!]\s*$/.test(tail);
              const timeTrigger = now - state.lastSoftEmitAt > softThrottle;
              if (tail && (charTrigger || punctuationTrigger || !state.lastSoftText) && timeTrigger) {
                state.lastSoftEmitAt = now;
                state.lastSoftText = tail;
                postPatch(tail, 'soft', event.result);
              } else if (!tail) {
                state.lastSoftText = '';
              }

              setTelemetry(`Soft v${state.version + 1} · tail ${tail.length} chars`);
            };

            recognizer.recognized = (_, event) => {
              // Map reason code to text (NoMatch=0, RecognizedSpeech=3, Canceled=2)
              const reasonText = event?.result?.reason === 0
                ? 'NoMatch'
                : event?.result?.reason === 3
                ? 'RecognizedSpeech'
                : event?.result?.reason === 2
                ? 'Canceled'
                : `Unknown(${event?.result?.reason})`;

              log('Recognized (final) event', {
                reason: reasonText,
                text: event?.result?.text?.substring(0, 50) || '(empty)'
              });

              // Log NoMatch only if it's unexpected (not just silence)
              if (event?.result?.reason === 0 && event?.result?.text !== '') {
                log('⚠️ NoMatch', { lang: state.sourceLang });
              }

              if (!event || !event.result) {
                return;
              }
              if (event.result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
                const finalText = (event.result.text || '').trim();
                if (!finalText) {
                  resetPrefixState();
                  state.lastPartialFull = '';
                  state.lastSoftText = '';
                  state.lastSoftEmitAt = 0;
                  return;
                }
                state.lastPartialFull = finalText;
                const activeConfig = state.config || DEFAULT_CONFIG;
                const delay = Math.max(
                  Number(activeConfig.finalDebounceMs ?? DEFAULT_CONFIG.finalDebounceMs) || 0,
                  0
                );
                const remainder = computeFinalRemainder(finalText);
                const trimmedRemainder = remainder.trim();
                const split = trimmedRemainder ? splitSentences(trimmedRemainder) : [];
                const segments = split.length
                  ? split
                  : trimmedRemainder
                  ? [trimmedRemainder]
                  : [];
                clearTimeout(state.finalTimer);
                state.finalTimer = null;

                const emitFinalSegments = () => {
                  let emitted = 0;
                  for (const sentence of segments) {
                    if (sentence) {
                      emitHardSegment(sentence, event.result);
                      emitted += 1;
                    }
                  }
                  state.lastSoftText = '';
                  state.lastSoftEmitAt = 0;
                  state.lastPartialFull = '';
                  resetPrefixState();
                  state.finalTimer = null;
                  setTelemetry(
                    emitted
                      ? `Hard ✔︎ · ${emitted} segment${emitted > 1 ? 's' : ''}`
                      : 'Hard ✔︎ · prefix only'
                  );
                };

                if (delay > 0) {
                  state.finalTimer = setTimeout(() => {
                    state.finalTimer = null;
                    emitFinalSegments();
                  }, delay);
                } else {
                  emitFinalSegments();
                }
              } else if (event.result.reason === SpeechSDK.ResultReason.NoMatch) {
                log('No speech match', { reason: event.result.noMatchDetails });
              }
            };

            recognizer.canceled = (_, event) => {
              setStatus('Canceled');
              log('Recognition canceled', { reason: event.reason, error: event.errorDetails });
            };

            recognizer.sessionStarted = () => {
              setStatus('Listening');
              log('Session started');
            };

            recognizer.sessionStopped = () => {
              setStatus('Stopped');
              log('Session stopped');
              stop();
            };

            recognizer.speechStartDetected = (_, event) => {
              log('Speech start detected!', { offset: event?.offset });
            };

            recognizer.speechEndDetected = (_, event) => {
              log('Speech end detected', { offset: event?.offset });
            };

            recognizer.startContinuousRecognitionAsync(
              () => {
                setStatus('Listening');
                log('Recognition started', {
                  lang: state.sourceLang,
                  targets: state.targetLangs
                });
                scheduleTokenRefresh();
              },
              (err) => {
                log('Failed to start recognition', { error: err?.message });
                stop();
              }
            );
          } catch (err) {
            log('Start failed', { error: err?.message });
            stop();
          }
        }

        function stop() {
          clearTokenRefresh();
          stopHeartbeat();
          clearTimeout(state.finalTimer);
          state.finalTimer = null;
          state.lastSoftEmitAt = 0;
          state.lastSoftText = '';
          state.lastPartialFull = '';
          resetPrefixState();
          if (state.recognizer) {
            try {
              state.recognizer.stopContinuousRecognitionAsync(() => {
                log('Recognition stopped');
              });
            } catch (err) {
              log('Error stopping recognizer', { error: err?.message });
            }
            state.recognizer = null;
          }
          if (state.ws) {
            state.ws.close(1000, 'Stopping');
            state.ws = null;
          }
          if (state.phraseList && typeof state.phraseList.clear === 'function') {
            state.phraseList.clear();
          }
          state.phraseList = null;
          state.patchSourceLang = null;
          state.tokenRegion = null;
          startBtn.disabled = false;
          stopBtn.disabled = true;
          setStatus('Idle');
          setTelemetry('—');
        }

        // Enumerate and populate microphone devices
        async function populateMicrophoneList() {
          try {
            const micSelect = document.getElementById('micSelect');

            // Request microphone permission first to get device labels
            await navigator.mediaDevices.getUserMedia({ audio: true })
              .then(stream => stream.getTracks().forEach(track => track.stop()));

            const devices = await navigator.mediaDevices.enumerateDevices();
            const audioInputs = devices.filter(device => device.kind === 'audioinput');

            // Clear existing options except the default
            micSelect.innerHTML = '<option value="">Default microphone</option>';

            // Add each microphone as an option
            audioInputs.forEach(device => {
              const option = document.createElement('option');
              option.value = device.deviceId;
              option.textContent = device.label || `Microphone ${device.deviceId.substring(0, 8)}`;
              micSelect.appendChild(option);
            });

            log('Microphone devices enumerated', { count: audioInputs.length });
          } catch (err) {
            log('Failed to enumerate microphones', { error: err?.message });
          }
        }

        // Populate microphones on page load
        populateMicrophoneList();

        loadConfig().catch((err) => log('Config bootstrap failed', { error: err?.message }));

        startBtn.addEventListener('click', () => {
          start();
        });
        stopBtn.addEventListener('click', () => {
          stop();
        });

        copyDebugBtn.addEventListener('click', async () => {
          try {
            await navigator.clipboard.writeText(logArea.textContent);
            const originalText = copyDebugBtn.textContent;
            copyDebugBtn.textContent = 'Copied!';
            setTimeout(() => {
              copyDebugBtn.textContent = originalText;
            }, 2000);
          } catch (err) {
            alert('Failed to copy: ' + err.message);
          }
        });

        window.addEventListener('beforeunload', stop);
      })();
    </script>
  </body>
</html>
